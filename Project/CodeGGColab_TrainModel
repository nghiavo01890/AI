#
from google.colab import drive
drive.mount('/content/drive')

#
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os
import keras
import tensorflow as tf

#
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint
from keras import datasets,Sequential,callbacks
from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from keras.layers import Dense,Activation,BatchNormalization,Dropout
from keras.models import Sequential
from tensorflow.keras.utils import to_categorical
from keras import callbacks
from sklearn.metrics import precision_score, recall_score,confusion_matrix,classification_report,accuracy_score,f1_score
from keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import RMSprop
from matplotlib import scale
from sklearn.metrics import confusion_matrix
from keras.utils import np_utils
from keras.preprocessing.image import load_img, img_to_array,array_to_img,ImageDataGenerator, image
from tensorflow.keras.optimizers import RMSprop, SGD
import os
from keras.models import load_model

from sklearn import preprocessing
from sklearn.preprocessing import OneHotEncoder, LabelEncoder

#
animal = ['Cat','Chicken','Cow','Dog','Horse', 'Sheep'] 

dir_train = '/content/drive/MyDrive/data/Upload/Train_set' 
dir_test = '/content/drive/MyDrive/data/Upload/Test_set'

listpath = []
x_train = []
y_train = []
x_test = []
y_test = []

#
size_img=48

def create_data(dir, x_train, y_train):
  for i in animal:
    path = os.path.join(dir,i)
    index_label = animal.index(i)
    for j in os.listdir(path):
      img_path = os.path.join(path, j)
      img = image.load_img(img_path, target_size=(int(size_img), int(size_img)))
      img = img_to_array(img)
      img = img.reshape(int(size_img), int(size_img), 3) 
      img = img.astype('float32')
      img = img/255
      x_train.append(img) #Data
      y_train.append(index_label)

create_data(dir_train, x_train, y_train) #tạo dữ liệu 
create_data(dir_test, x_test, y_test)

#
x_train = np.array(x_train)
y_train = np.array(y_train)
y_train = np_utils.to_categorical(y_train, 6)
print(x_train.shape)
print(y_train.shape)

x_test = np.array(x_test)
y_test = np.array(y_test)
y_test = np_utils.to_categorical(y_test, 6)
print(x_test.shape)
print(y_test.shape)

#
model = Sequential()

model.add(Conv2D(filters=32,
                 kernel_size=(27,48),
                 activation='relu',
                 kernel_initializer='he_uniform',
                 padding='same',
                 input_shape=(int(size_img),int(size_img),3),
                 strides=(2,2)))

model.add(MaxPooling2D(2,2))

model.add(Conv2D(filters=64,
                 kernel_size=(27,48), 
                 activation='relu',
                 kernel_initializer='he_uniform',
                 padding='same'))

model.add(MaxPooling2D(2,2))

model.add(Flatten())

model.add(Dense(512, activation='relu',input_shape=(691200,), name='layer1')) #691200=360x640
model.add(Dense(1028, activation='relu', name='layer2'))
model.add(Dense(1028, activation='relu', name='layer3'))
model.add(Dense(6, activation='softmax', name='layer4'))

model.summary()

model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])

#
callback1 = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)
filepath="checkpoint.h5"
callback2 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')

#
history = model.fit(x_train, y_train, batch_size=64, epochs=50, verbose=1, validation_data=(x_test, y_test), callbacks=[callback1, callback2])
